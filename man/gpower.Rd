% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gpower.R
\name{gpower}
\alias{gpower}
\title{Compute Sparse PCA using GPower method}
\usage{
gpower(
  A,
  k,
  rho,
  penalty = c("l0", "l1"),
  center = c(TRUE, FALSE),
  block = c(TRUE, FALSE),
  mu = NA,
  iter_max = 1000,
  epsilon = 1e-04
)
}
\arguments{
\item{A}{Input matrix of size (p x n) with p < n.}

\item{k}{Number of components, 0 < k < p.}

\item{rho}{Relative sparsity weight factor of the optimization. Either a
vector of floats of size k or float which will be repeated k times. 0 < rho
< 1.}

\item{penalty}{Penalty type to use in the optimization. Either "l0" or "l1".
The default is "l1" since it performed best in experiments.}

\item{center}{Centers the data. Either TRUE or FALSE. Default is TRUE.}

\item{block}{Optimization method. If FALSE, the components are calculated
individually. If TRUE, all components are calculated at the same time.
Default is FALSE.}

\item{mu}{Mean to be applied to each component in the block. Either a vector
of float of size k or a float which will be repeated k times. Only used if
block is TRUE. Default is FALSE.}

\item{iter_max}{Maximum iterations when adjusting components with
gradient descent. Default is 1000.}

\item{epsilon}{Epsilon of the gradient descent stopping function. Default is
1e-4.}
}
\value{
List containing: \describe{
  \item{loadings}{The PCA components}
  \item{scores}{Scores of the components on A}
  \item{a_approx}{Reconstructed version of A using the components}
  \item{prop_sparse}{Proportion of sparsity of the components}
  \item{exp_var}{Explained ratio of variance of the components}
  \item{centers}{Centers of matrix A if center == TRUE}
}
}
\description{
Generalized power method for sparse principal component analysis. Implements
the method developed by Journee et al. (2010) with a choice between a L1 and
L0 penalty and a column based and block approach.
}
\details{
GPower uses four different optimization procedures for the four combinations
between l0 and l1 penalty and single-unit or block computation. With the l0
penalty, the cardinality of the solutions is penalized. The objective
function of the single unit case with l1 penalty is
\denq{\phi_{l_{1}}^{2}(\gamma) = \max_{x\in S^{p}}\sum_{i=1}^{n}{\left [
\left |  a_{i}^{T}x\right | - \gamma  \right ]_{+}^{2}}}
where x represents the components and gamma is the penalty.
For the single unit case with the l0 penalty, the following function is used
\denq{\phi_{l_{0}}^{2}(\gamma) = \max_{x\in S^{p}}\sum_{i=1}^{n}{\left [
\left ( a_{i}^{T} x \right )^{2} - \gamma  \right ]_{+}}}
Where the results are squared before gamma is subtracted instead of after.
For the block cases, the following functions are used. First the case with l1
penalty
\denq{\phi_{l_{1},m}^{2}(\gamma) = \max_{x\in S^{p}}\sum_{j=1}^{m}{\sum_{i=1}
^{n}{\left [ \mu_{j} \left | a_{i}^{T}x_{j} \right | - \gamma_{j} \right ]_
{+}^{2}}}}
and for the l0 penalty
\denq{\phi_{l_{0},m}(\gamma) = \max_{x\in S^{p}}\sum_{j=1}^{m}{\sum_{i=1}^{n}
{ \left [ \left ( \mu_{j} a_{i}^{T}x_{j} \right )^{2} - \gamma_{j} \right ]_
{+}}}}
All of these functions are optimized using gradient decent. In this
implementation, a relative penalty is implemented with rho. Gamma is
calculated using rho and the maximal norm value.
}
\examples{
set.seed(360)
p <- 20
n <- 50
k <- 5
A <- scale(matrix(rnorm(p * n), nrow = p, ncol = n), scale = FALSE)
rho <- 0.1
# rho <- c(0.1, 0.2, 0.1, 0.2, 0.1)
mu <- 1
# mu <- c(1, 1.5, 0.5, 2, 1)

# Single unit with l1 penalty
gpower(A, k, rho, 'l1', FALSE)

# Single unit with l0 penalty
gpower(A, k, rho, 'l0', FALSE)

# Block with l1 penalty
gpower(A, k, rho, 'l1', FALSE, TRUE, mu)

# Block with l0 penalty
gpower(A, k, rho, 'l0', FALSE, TRUE, mu)

}
\references{
Journee, M., Nesterov, Y., Richtarik, P. and Sepulchre, R. (2010)
Generalized Power Method for Sparse Principal Component Analysis.
*Journal of Machine Learning Research. 11*, 517-553.
}
